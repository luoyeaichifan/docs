---
name: shell常用
sort: 0
---

-  全词过滤,去掉空格

```
cat test.txt
carbon_address_ip_28 = 10.39.40.182
carbon_address_ip = 10.13.80.104
#carbon_address_ip = 10.39.40.183
#carbon_address_ip = 10.39.40.26

cat test.txt | grep -w carbon_address_ip | grep -v "#" | awk -F "=" '{print $2}' |sed s/[[:space:]]//g

```

- 写文件

```
cat << EOF 	> /etc/shadowsocks.json
{ 
 "server": "$1",
 "server_port": $2,
 "local_address": "127.0.0.1",
 "local_port": 1080, 
 "password": "$3",
 "timeout": 600,
 "method": "$4" 
}
EOF

#ps aufx | grep sslocal | grep -v grep | awk -F " " '{print $2}' | xargs -i kill -9 {}
cat /etc/shadowsocks.json
sslocal -c /etc/shadowsocks.json -d restart /dev/null 2>&1 &
curl --socks5 127.0.0.1:1080 http://httpbin.org/i

sh /home/go/shell/fly.sh 162.243.134.235 16896 isx.yt-84649090 aes-256-cfb
```

- 发包测试脚本

```
cat sleep.sh 
x=0
ps aufx | grep curl | grep -v grep | awk -F " " '{print $2}' | xargs -I {} kill -9 {}
sh curl.sh &
while true
do

    if [ $x == 500 ];then
        #echo 1000
        #ps aufx | grep curl | grep -v grep | awk -F " " '{print $2}' | xargs -I {} echo {}
        ps aufx | grep curl | grep -v grep | awk -F " " '{print $2}' | xargs -I {} kill -9 {} >/dev/null 2>&1
        sleep 1
        x=0
        sh curl.sh &
    fi
    x=`expr $x + 1`
done


 cat curl.sh 
#!/bin/bash
read_line()
{
    read
    while [ $? -eq 0 ]
    do
        #echo $REPLY  # 换成你想做的事情
    url=\"UrlPath\":\"$REPLY\"
    #echo $url
    #curl 10.212.81.164:8081/debug -X POST -H "Content-Type:application/json" -d '{"PprofStart":0,"PprofStop":0,"UseMerge":1,"Compare":1,${url},”Clear”:0}' 
    #echo '{"PprofStart":0,"PprofStop":0,"UseMerge":1,"Compare":1,'${url}',”Clear”:0}'
    curl 10.39.40.26:8081/debug -X POST -H "Content-Type:application/json" -d '{"PprofStart":0,"PprofStop":0,"UseMerge":1,"CompareCurl":1,'${url}',"Clear":0,"CompareFile":0}'  >/dev/null 2>&1
        read
    done
}

#tail -f write_test | read_line
tail -f  noc-api.log | grep " match " | grep -E "metrics\/find\/|\/render\/|\/tree\/" | awk -F "GET " '{print $2}' | awk -F " " '{print $1}' | awk -F " HTTP/1.1" '{print $1}' | read_line


sh sleep.sh >/dev/null 2>&1 &


0> cat kill.sh 
ps aufx | grep sleep.sh | grep -v grep | awk -F ' ' '{print $2}' | xargs -I {} kill -9 {}
ps aufx | grep curl | grep -v grep | awk -F " " '{print $2}' | xargs -I {} kill -9 {}
ps aufx | grep curl
ps aufx | grep sleep
```

- 发包脚本

```
0>cat sendip.sh 
while true
do
sendip  -p  ipv4 -is 2.2.2.2 -id 10.39.40.26 -p udp -ud 8333 -f package1 10.13.80.98
sendip  -p  ipv4 -is 2.2.2.2 -id 10.39.40.26 -p udp -ud 8333 -f package2 10.13.80.98
done
```

- 匹配子串

```
匹配子串，保存匹配的字符，如s/(love)able/\1rs，loveable被替换成lovers。
```

- 判断存在与否

```
cat tmp.sh 
#!/bin/bash

#params: conf_item_name,  conf_item_value, conf_file
#not support conf item name with "." for now. and only for toml conf file.

#  相等返回0,不等返回1,错误返回2
CONF_ITEM_NAME=$1
CONF_ITEM_VALUE=$2
CONF_FILE=$3

if [[ $CONF_ITEM_NAME == "" || $CONF_ITEM_VALUE == "" || $CONF_FILE == "" ]]; then
    echo "Invalid params, should be: conf_item_name,  conf_item_value, conf_file"
    exit 2
fi

if [[ ! -f $CONF_FILE ]]; then
   echo "Error: $CONF_FILE does not exist."
   exit 2
fi


RET=`cat $CONF_FILE | grep $CONF_ITEM_NAME | grep -v grep`

RET=`cat $CONF_FILE | grep -E "$CONF_ITEM_NAME\s*=\s*" | grep -v "#" | awk -F "=" '{print $2}' |sed s/[[:space:]]//g | grep -v grep`
echo RET=$RET
LEN=`cat $CONF_FILE | grep -E "$CONF_ITEM_NAME\s*=\s*" | grep -v "#" | awk -F "=" '{print $2}' |sed s/[[:space:]]//g | grep -v grep | wc -l`
echo LEN$LEN
if [[ $LEN == "1" ]]; then
    if [[ $RET == $CONF_ITEM_VALUE ]]; then
	echo "equal"
    	exit 0
    fi
    echo "not equal"
    exit 1
fi
echo "more than one value"
exit 2
```

- 后台启动带错误输出

```
nohup ./beeweb >> proxy.log 2>&1 &
```

- 字符串文件,取出数量比较多的前1000个

```
cat raw.txt | sort |uniq -c |sort -nr | head



[~/work/go/here]$cat raw.txt 
aa
aa
aa
bb
cc
abc
abc
cc
aaa
[~/work/go/here]$cat raw.txt | sort | uniq -c | sort -nr | head
   3 aa
   2 cc
   2 abc
   1 bb
   1 aaa
   
```



- sort 

```
排序选项：

-b, --ignore-leading-blanks	忽略前导的空白区域
-d, --dictionary-order	只考虑空白区域和字母字符
-f, --ignore-case	忽略字母大小写
-g, --general-numeric-sort	按照常规数值排序
-i, --ignore-nonprinting	只排序可打印字符
-n, --numeric-sort	根据字符串数值比较
-r, --reverse	逆序输出排序结果

其他选项：

-c, --check, --check=diagnose-first	检查输入是否已排序，若已有序则不进行操作
-k, --key=位置1[,位置2]	在位置1 开始一个key，在位置2 终止(默认为行尾)
-m, --merge	合并已排序的文件，不再进行排序
-o, --output=文件	将结果写入到文件而非标准输出
-t, --field-separator=分隔符	使用指定的分隔符代替非空格到空格的转换
-u, --unique	配合-c，严格校验排序；不配合-c，则只输出一次排序结果

```

- uniq 

```
从输入文件或者标准输入中筛选相邻的匹配行,并写入到输出文件或标准输出

-c, --count           在每行前加上表示相应行目出现次数的前缀编号
  -d, --repeated        只输出重复的行
  -D, --all-repeated[=delimit-method    显示所有重复的行
                        delimit-method={none(default),prepend,separate}
                        以空行为界限
  -f, --skip-fields=N   比较时跳过前N 列
  -i, --ignore-case     在比较的时候不区分大小写
  -s, --skip-chars=N    比较时跳过前N 个字符
  -u, --unique          只显示唯一的行
  -z, --zero-terminated 使用'\0'作为行结束符，而不是新换行
  -w, --check-chars=N   对每行第N 个字符以后的内容不作对照
      --help            显示此帮助信息并退出
      --version         显示版本信息并退出
```

- 词频统计

```
写一个 bash 脚本以统计一个文本文件 words.txt 中每个单词出现的频率。

为了简单起见，你可以假设：

words.txt只包括小写字母和 ' ' 。
每个单词只由小写字母组成。
单词间由一个或多个空格字符分隔。
示例:

假设 words.txt 内容如下：

the day is sunny the the
the sunny is is
你的脚本应当输出（以词频降序排列）：

the 4
is 3
sunny 2
day 1
说明:

不要担心词频相同的单词的排序问题，每个单词出现的频率都是唯一的。
你可以使用一行 Unix pipes 实现吗？
```


```
awk '{for(i=1;i<=NF;i++){res[$i]+=1}}END{for(key in res){print k" "res[k]}}' words.txt | sort -nr -k2
```


- 有效的电话号码

```
给定一个包含电话号码列表（一行一个电话号码）的文本文件 file.txt，写一个 bash 脚本输出所有有效的电话号码。

你可以假设一个有效的电话号码必须满足以下两种格式： (xxx) xxx-xxxx 或 xxx-xxx-xxxx。（x 表示一个数字）

你也可以假设每行前后没有多余的空格字符。

示例:

假设 file.txt 内容如下：

987-123-4567
123 456 7890
(123) 456-7890
你的脚本应当输出下列有效的电话号码：

987-123-4567
(123) 456-7890
```

```
grep -P "^(\d{3}-|\(\d{3}\)\s)\d{3}-\d{4}$" file.txt
egrep "(^\([0-9]{3}\)\s[0-9]{3}-[0-9]{4}$|^[0-9]{3}-[0-9]{3}-[0-9]{4}$)"  file.txt
```

- 转置文件

```
给定一个文件 file.txt，转置它的内容。

你可以假设每行列数相同，并且每个字段由 ' ' 分隔.

示例:

假设 file.txt 文件内容如下：

name age
alice 21
ryan 30
应当输出：

name alice ryan
age 21 30
```

```
awk '{for(i=1;i<=NF;i++) {if(NR==1){res[i]=$i;}else{res[i]=res[i]" "$i} } }END{for(i=1;i<=NF;i++) print res[i]} ' file.txt

awk '{for(i=1;i<=NF;i++){if(NR==1){res[i]=$i}else{res[i]=res[i]" "$i}}}END{for(i=1;i<=length(res);i++){print res[i]}}' test.txt 
```

